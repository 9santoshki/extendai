# ===========================================
# AI Agent Backend Configuration
# Custom OpenAI-Compatible API
# ===========================================

# Local Model Configuration
# API key can be any value for local models
OPENAI_API_KEY=ollama

# Model name (adjust version if needed)
# Options: qwen2.5, qwen2.5:7b, qwen2.5:14b, etc.
MODEL_NAME=qwen2.5:0.5b

# Custom API endpoint for LLM service
BASE_URL=http://localhost:11434/v1

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Logging
LOG_LEVEL=INFO

# ===========================================
# Instructions:
# ===========================================
# 1. Make sure Ollama is running:
#    $ ollama serve
#
# 2. Verify qwen2.5 is installed:
#    $ ollama list
#    If not, install it:
#    $ ollama pull qwen2.5
#
# 3. Start the backend:
#    $ ./start.sh
#
# 4. Test it:
#    $ curl http://localhost:8000/health
# ===========================================
